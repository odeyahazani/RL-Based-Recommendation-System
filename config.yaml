device: cpu
seed: 42
state_dim: 84

# ------------------------------------------------------------------
env:
  max_steps: 30
  reward_mode: "shaped"
  slate_size: 5
  movies_per_genre: 50

# ------------------------------------------------------------------
agent:
  hidden_dim: 256
  batch_size: 64          # ↑ larger mini-batch for stabler updates
  lr: 0.0001
  gamma: 0.99
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay_steps: 20000
  tau: 0.01              # ← NEW - Polyak soft-update rate
  target_update_freq: 0  # hard sync no longer used (kept for completeness)

# ------------------------------------------------------------------
train:
  episodes: 500          # ↑ give the agent enough interactions
  checkpoint_every: 50
  log_every: 10
  save_dir: checkpoints/

# ------------------------------------------------------------------
replay_buffer:
  capacity: 10000
  per: true
  alpha: 0.6
  beta_start: 0.4
  beta_end: 1.0
  beta_steps: 100000
  eps_priority: 1e-6

# ------------------------------------------------------------------
eval:
  episodes: 100
  ckpt_file: ep0500.pt    # after the longer training
  csv_out: eval/metrics.csv
  engagement_thresholds: [0.1, 0.2, 0.3, 0.4, 0.5]
  # engagement_threshold: 0.3   # (fallback single value)

# ------------------------------------------------------------------
logging:
  enable: true            # turn off if you don't want TensorBoard
  log_dir: runs/